{
 "cells": [
  {
   "source": [
    "# NS_03 Group Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import datetime\n",
    "import sklearn.metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data_set, and calculate the mean and std of dataset\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # 0 -> mask  1-> nonmask  2 -> not a person\n",
    "# train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "\n",
    "# # calculate mean of imgs in each RGB channel\n",
    "# imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
    "# print(imgs.shape)\n",
    "\n",
    "# imgs.view(3, -1).mean(dim=1)  # mean of (number of imgs) in each channel\n",
    "# imgs.view(3, -1).std(dim=1) # std of (number of imgs) in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset, normarlize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "    # transforms.CenterCrop(256)   #中心剪裁后四周padding补充 (后续可以padding)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4990, 0.4567, 0.4188], std=[0.2913, 0.2778, 0.2836]) \n",
    "])\n",
    "\n",
    "# 0 -> mask  1-> nonmask  2 -> not a person\n",
    "train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder('./data/test', transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), # in=3x256x256; out=32x256x256\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=32x128x128\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1), # in=32x128x128, out=16x128x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=16x64x64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # in=16x64x64, out=8x64x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=8x32x32,\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 16x16\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64*16*16, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(1024, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(32, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv layer\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() \n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train_loop function\n",
    "def train_loop(n_epochs, optimizer, model, loss_fn, train_loader, verbose=1):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_dataloader: # loop over batches in dataset\n",
    "            # move data to GPU if available\n",
    "            imgs = imgs.to(device=device)  \n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)  # feed a batch through our model\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # computes the loss\n",
    "            \n",
    "            optimizer.zero_grad()  # getting rid of the gradients from the last round\n",
    "            \n",
    "            loss.backward()  # performs backward step, compute the gradients of all parameters\n",
    "            \n",
    "            optimizer.step()  # updates the model\n",
    "            \n",
    "            loss_train += loss.item() # sums of losses we saw over the epoch\n",
    "\n",
    "        if verbose == 1: \n",
    "        # print the average loss per batch, in epoch%10 == 0 \n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch, loss_train/len(train_loader)\n",
    "            ))\n",
    "        else:\n",
    "            if epoch == 1 or epoch % 5 == 0:\n",
    "                print('{} Epoch {}, Training loss {}'.format(\n",
    "                    datetime.datetime.now(), epoch, loss_train/len(train_loader)\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16837043,\n",
       " [432, 16, 2304, 16, 4608, 32, 18432, 64, 16777216, 1024, 32768, 32, 96, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "model = CNN().to(device=device)  # instantiates cnn model\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list   # number of parameters, and their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform training\n",
    "\n",
    "learning_rate = 0.001\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()  # use cross entropy loss function\n",
    "\n",
    "if 'my_model_2.pkl' not in os.listdir():\n",
    "    # call train_loop() function\n",
    "    train_loop(\n",
    "        n_epochs = 15,\n",
    "        optimizer = optimizer,\n",
    "        model = model,\n",
    "        loss_fn = loss_fn,\n",
    "        train_loader = train_dataloader\n",
    "    )\n",
    "    torch.save(model, 'my_model_2.pkl')\n",
    "else:\n",
    "    model = torch.load('my_model_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validate function\n",
    "def validate(model, loaders, names):\n",
    "    model.eval()\n",
    "    acc = []\n",
    "    cm = []\n",
    "    # accuracy on training data and test data\n",
    "    for name, loader in zip(names, loaders):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_predicted = []\n",
    "        total_labels = []\n",
    "        \n",
    "        with torch.no_grad(): # do not want gradients here, as we will not want to update parameters\n",
    "            for imgs, labels in loader:\n",
    "                # move data to GPU if available\n",
    "                imgs = imgs.to(device=device)  \n",
    "                labels = labels.to(device=device)\n",
    "                total_labels.append(labels)\n",
    "                \n",
    "                # feed input to models\n",
    "                outputs = model(imgs)  \n",
    "                \n",
    "                # gives the index of the highest value as output\n",
    "                _, predicted = torch.max(outputs, dim=1)  \n",
    "                total_predicted.append(predicted)\n",
    "                \n",
    "                # counts the number of example, total is increased by the batch size\n",
    "                total += labels.shape[0]  \n",
    "            \n",
    "                correct += int((predicted == labels).sum()) \n",
    "                \n",
    "        total_predicted = torch.hstack(total_predicted).cpu()\n",
    "        total_labels = torch.hstack(total_labels).cpu()\n",
    "        \n",
    "        print(\"Accuracy {}: {:.4f}\".format(name, correct / total))  \n",
    "        print(sklearn.metrics.classification_report(total_labels, total_predicted))\n",
    "        print(sklearn.metrics.confusion_matrix(total_labels, total_predicted))\n",
    "        print()\n",
    "        acc.append(correct / total)\n",
    "        cm.append(sklearn.metrics.confusion_matrix(total_labels, total_predicted))\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.9958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       284\n",
      "           1       0.99      1.00      1.00       338\n",
      "           2       1.00      1.00      1.00       576\n",
      "\n",
      "    accuracy                           1.00      1198\n",
      "   macro avg       1.00      1.00      1.00      1198\n",
      "weighted avg       1.00      1.00      1.00      1198\n",
      "\n",
      "[[281   1   2]\n",
      " [  0 338   0]\n",
      " [  0   2 574]]\n",
      "\n",
      "Accuracy test: 0.8424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79       123\n",
      "           1       0.88      0.94      0.91       124\n",
      "           2       0.74      0.91      0.82       102\n",
      "\n",
      "    accuracy                           0.84       349\n",
      "   macro avg       0.85      0.85      0.84       349\n",
      "weighted avg       0.86      0.84      0.84       349\n",
      "\n",
      "[[ 85  11  27]\n",
      " [  2 116   6]\n",
      " [  4   5  93]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measuring accuracy\n",
    "validate(model, [train_dataloader, test_dataloader], ['train', 'test']);"
   ]
  },
  {
   "source": [
    "## Part 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Run model on Female test dataset and Male dataset, evaluate their performances.\n",
    "- Compare their performances, check whether our model has gender bias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Male: 0.8131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        93\n",
      "           1       0.84      0.98      0.91       105\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81       198\n",
      "   macro avg       0.61      0.53      0.56       198\n",
      "weighted avg       0.92      0.81      0.84       198\n",
      "\n",
      "[[ 58  19  16]\n",
      " [  0 103   2]\n",
      " [  0   0   0]]\n",
      "\n",
      "/Users/zoufan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Accuracy Female: 0.8450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83        91\n",
      "           1       0.94      0.94      0.94       109\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.64      0.56      0.59       200\n",
      "weighted avg       0.96      0.84      0.89       200\n",
      "\n",
      "[[ 66   6  19]\n",
      " [  2 103   4]\n",
      " [  0   0   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "male_dataset = ImageFolder('./data/test_male', transform=transform)\n",
    "male_dataloader = DataLoader(male_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "female_dataset = ImageFolder('./data/test_female', transform=transform)\n",
    "female_dataloader = DataLoader(female_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "validate(model, [male_dataloader, female_dataloader], ['Male', 'Female']);\n"
   ]
  },
  {
   "source": [
    "Accuracy of female is 0.84, while accuracy of male is 0.81. Our model has a bias of predicting male with mask as not wearing mask incorrectly.\n",
    "\n",
    "The reason for this gender bias is that our training dataset is not balance in terms of gender. For example, the training images in Mask folder contains 164 female images, and only 120 male images.\n",
    "\n",
    "To address this bias, we modified our training dataset, and balanced the number of male images and female images. And then re-training our cnn model on this balanced dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load balanced dataset\n",
    "train_balance_dataset = ImageFolder('./data/train_balance', transform=transform)\n",
    "train_balance_dataloader = DataLoader(train_balance_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# perform training\n",
    "model_retrained = CNN().to(device=device) \n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model_retrained.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()  # use cross entropy loss function\n",
    "\n",
    "if 'my_model_balance.pkl' not in os.listdir():\n",
    "    # call train_loop() function\n",
    "    train_loop(\n",
    "        n_epochs = 15,\n",
    "        optimizer = optimizer,\n",
    "        model = model_retrained,\n",
    "        loss_fn = loss_fn,\n",
    "        train_loader = train_balance_dataloader\n",
    "    )\n",
    "    torch.save(model_retrained, 'my_model_balance.pkl')\n",
    "else:\n",
    "    model_retrained = torch.load('my_model_balance.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.9879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       327\n",
      "           1       0.99      0.99      0.99       338\n",
      "           2       0.99      1.00      0.99       576\n",
      "\n",
      "    accuracy                           0.99      1241\n",
      "   macro avg       0.99      0.99      0.99      1241\n",
      "weighted avg       0.99      0.99      0.99      1241\n",
      "\n",
      "[[316   3   8]\n",
      " [  2 336   0]\n",
      " [  1   1 574]]\n",
      "\n",
      "Accuracy test: 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       123\n",
      "           1       0.93      0.91      0.92       124\n",
      "           2       0.81      0.91      0.86       102\n",
      "\n",
      "    accuracy                           0.89       349\n",
      "   macro avg       0.88      0.89      0.88       349\n",
      "weighted avg       0.89      0.89      0.89       349\n",
      "\n",
      "[[103   6  14]\n",
      " [  3 113   8]\n",
      " [  6   3  93]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation on training and test dataset\n",
    "validate(model_retrained, [train_balance_dataloader, test_dataloader], ['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Male: 0.8485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85        93\n",
      "           1       0.92      0.93      0.93       105\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85       198\n",
      "   macro avg       0.64      0.56      0.59       198\n",
      "weighted avg       0.95      0.85      0.89       198\n",
      "\n",
      "[[70  8 15]\n",
      " [ 1 98  6]\n",
      " [ 0  0  0]]\n",
      "\n",
      "Accuracy Female: 0.9100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91        91\n",
      "           1       0.96      0.95      0.96       109\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.65      0.60      0.62       200\n",
      "weighted avg       0.97      0.91      0.94       200\n",
      "\n",
      "[[ 78   4   9]\n",
      " [  2 104   3]\n",
      " [  0   0   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation on Female and Male test dataset\n",
    "validate(model_retrained, [male_dataloader, female_dataloader], ['Male', 'Female']);"
   ]
  },
  {
   "source": [
    "### K-Fold cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Merge original training dataset and test dataset\n",
    "total_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# Merge re-balanced training dataset and test dataset\n",
    "total_balanced_dataset = torch.utils.data.ConcatDataset([train_balance_dataset, test_dataset])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 187,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------- 1th split -------------\n",
      "2021-04-22 12:12:27.178630 Epoch 1, Training loss 0.8201574141328986\n",
      "2021-04-22 12:16:15.055452 Epoch 5, Training loss 0.33897835558111017\n",
      "2021-04-22 12:21:05.581536 Epoch 10, Training loss 0.11315209433351728\n",
      "2021-04-22 12:25:49.854063 Epoch 15, Training loss 0.03873375355297784\n",
      "Accuracy Train: 0.9641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       366\n",
      "           1       0.97      0.99      0.98       416\n",
      "           2       0.96      0.98      0.97       610\n",
      "\n",
      "    accuracy                           0.96      1392\n",
      "   macro avg       0.97      0.96      0.96      1392\n",
      "weighted avg       0.96      0.96      0.96      1392\n",
      "\n",
      "[[336   8  22]\n",
      " [  2 410   4]\n",
      " [ 10   4 596]]\n",
      "\n",
      "Accuracy Test: 0.9548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91        41\n",
      "           1       0.92      1.00      0.96        46\n",
      "           2       1.00      0.96      0.98        68\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.95      0.95      0.95       155\n",
      "weighted avg       0.96      0.95      0.95       155\n",
      "\n",
      "[[37  4  0]\n",
      " [ 0 46  0]\n",
      " [ 3  0 65]]\n",
      "\n",
      "------------- 2th split -------------\n",
      "2021-04-22 12:27:06.474967 Epoch 1, Training loss 0.8754062097180974\n",
      "2021-04-22 12:30:55.447304 Epoch 5, Training loss 0.3709520897404714\n",
      "2021-04-22 12:35:38.968728 Epoch 10, Training loss 0.1931974251161922\n",
      "2021-04-22 12:40:22.716416 Epoch 15, Training loss 0.06625053584998981\n",
      "Accuracy Train: 0.9540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       366\n",
      "           1       0.97      0.95      0.96       416\n",
      "           2       0.94      0.98      0.96       610\n",
      "\n",
      "    accuracy                           0.95      1392\n",
      "   macro avg       0.96      0.95      0.95      1392\n",
      "weighted avg       0.95      0.95      0.95      1392\n",
      "\n",
      "[[338   9  19]\n",
      " [  2 395  19]\n",
      " [ 10   5 595]]\n",
      "\n",
      "Accuracy Test: 0.9548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        41\n",
      "           1       0.94      0.96      0.95        46\n",
      "           2       0.96      0.99      0.97        68\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.96      0.95      0.95       155\n",
      "weighted avg       0.96      0.95      0.95       155\n",
      "\n",
      "[[37  2  2]\n",
      " [ 1 44  1]\n",
      " [ 0  1 67]]\n",
      "\n",
      "------------- 3th split -------------\n",
      "2021-04-22 12:41:40.962137 Epoch 1, Training loss 0.9177035174586556\n",
      "2021-04-22 12:45:29.752978 Epoch 5, Training loss 0.399570092220198\n",
      "2021-04-22 12:50:13.622715 Epoch 10, Training loss 0.1551167184317654\n",
      "2021-04-22 12:54:57.936097 Epoch 15, Training loss 0.05424638375089588\n",
      "Accuracy Train: 0.9325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       366\n",
      "           1       0.91      0.97      0.94       416\n",
      "           2       0.96      0.91      0.94       610\n",
      "\n",
      "    accuracy                           0.93      1392\n",
      "   macro avg       0.93      0.93      0.93      1392\n",
      "weighted avg       0.93      0.93      0.93      1392\n",
      "\n",
      "[[335  16  15]\n",
      " [  5 405   6]\n",
      " [ 30  22 558]]\n",
      "\n",
      "Accuracy Test: 0.9226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89        41\n",
      "           1       0.90      0.96      0.93        46\n",
      "           2       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.92      0.92      0.92       155\n",
      "weighted avg       0.92      0.92      0.92       155\n",
      "\n",
      "[[35  4  2]\n",
      " [ 0 44  2]\n",
      " [ 3  1 64]]\n",
      "\n",
      "------------- 4th split -------------\n",
      "2021-04-22 12:56:14.604846 Epoch 1, Training loss 0.7512164251370863\n",
      "2021-04-22 13:00:02.862236 Epoch 5, Training loss 0.3189946115016937\n",
      "2021-04-22 13:04:49.495674 Epoch 10, Training loss 0.11651276385369287\n",
      "2021-04-22 13:09:36.668232 Epoch 15, Training loss 0.01889276527005925\n",
      "Accuracy Train: 0.9655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       366\n",
      "           1       0.96      0.99      0.98       416\n",
      "           2       0.96      0.98      0.97       610\n",
      "\n",
      "    accuracy                           0.97      1392\n",
      "   macro avg       0.97      0.96      0.96      1392\n",
      "weighted avg       0.97      0.97      0.97      1392\n",
      "\n",
      "[[336  11  19]\n",
      " [  1 411   4]\n",
      " [  9   4 597]]\n",
      "\n",
      "Accuracy Test: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        41\n",
      "           1       1.00      0.96      0.98        46\n",
      "           2       0.96      0.99      0.97        68\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.98      0.97      0.97       155\n",
      "weighted avg       0.97      0.97      0.97       155\n",
      "\n",
      "[[40  0  1]\n",
      " [ 0 44  2]\n",
      " [ 1  0 67]]\n",
      "\n",
      "------------- 5th split -------------\n",
      "2021-04-22 13:10:54.247848 Epoch 1, Training loss 0.8296214680780064\n",
      "2021-04-22 13:14:44.066545 Epoch 5, Training loss 0.3752993338487365\n",
      "2021-04-22 13:19:31.359119 Epoch 10, Training loss 0.1906871632249518\n",
      "2021-04-22 13:24:18.388096 Epoch 15, Training loss 0.05375689027873291\n",
      "Accuracy Train: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       366\n",
      "           1       0.97      0.98      0.98       416\n",
      "           2       0.96      0.98      0.97       610\n",
      "\n",
      "    accuracy                           0.97      1392\n",
      "   macro avg       0.97      0.96      0.97      1392\n",
      "weighted avg       0.97      0.97      0.97      1392\n",
      "\n",
      "[[342   7  17]\n",
      " [  1 408   7]\n",
      " [  8   5 597]]\n",
      "\n",
      "Accuracy Test: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        41\n",
      "           1       1.00      1.00      1.00        46\n",
      "           2       0.96      0.99      0.97        68\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.98      0.97      0.97       155\n",
      "weighted avg       0.97      0.97      0.97       155\n",
      "\n",
      "[[38  0  3]\n",
      " [ 0 46  0]\n",
      " [ 1  0 67]]\n",
      "\n",
      "------------- 6th split -------------\n",
      "2021-04-22 13:25:36.443665 Epoch 1, Training loss 0.8386185683987357\n",
      "2021-04-22 13:29:25.937190 Epoch 5, Training loss 0.3372510876506567\n",
      "2021-04-22 13:34:13.034579 Epoch 10, Training loss 0.05421311821026558\n",
      "2021-04-22 13:39:02.690684 Epoch 15, Training loss 0.011793906369183043\n",
      "Accuracy Train: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       366\n",
      "           1       0.98      0.98      0.98       416\n",
      "           2       0.96      0.98      0.97       610\n",
      "\n",
      "    accuracy                           0.97      1392\n",
      "   macro avg       0.97      0.96      0.97      1392\n",
      "weighted avg       0.97      0.97      0.97      1392\n",
      "\n",
      "[[340   6  20]\n",
      " [  2 408   6]\n",
      " [  9   2 599]]\n",
      "\n",
      "Accuracy Test: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        41\n",
      "           1       0.96      1.00      0.98        46\n",
      "           2       0.99      0.97      0.98        68\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.97      0.97      0.97       155\n",
      "weighted avg       0.97      0.97      0.97       155\n",
      "\n",
      "[[39  1  1]\n",
      " [ 0 46  0]\n",
      " [ 1  1 66]]\n",
      "\n",
      "------------- 7th split -------------\n",
      "2021-04-22 13:40:20.136450 Epoch 1, Training loss 0.7384192760695111\n",
      "2021-04-22 13:44:07.428890 Epoch 5, Training loss 0.3562880879776044\n",
      "2021-04-22 13:48:51.460671 Epoch 10, Training loss 0.11437309414825657\n",
      "2021-04-22 13:53:35.630518 Epoch 15, Training loss 0.09152183039325544\n",
      "Accuracy Train: 0.9174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       366\n",
      "           1       0.98      0.91      0.94       416\n",
      "           2       0.91      0.92      0.92       610\n",
      "\n",
      "    accuracy                           0.92      1392\n",
      "   macro avg       0.92      0.92      0.92      1392\n",
      "weighted avg       0.92      0.92      0.92      1392\n",
      "\n",
      "[[337   6  23]\n",
      " [  9 377  30]\n",
      " [ 45   2 563]]\n",
      "\n",
      "Accuracy Test: 0.9419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        41\n",
      "           1       1.00      0.98      0.99        46\n",
      "           2       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.94      0.95      0.94       155\n",
      "weighted avg       0.94      0.94      0.94       155\n",
      "\n",
      "[[39  0  2]\n",
      " [ 0 45  1]\n",
      " [ 6  0 62]]\n",
      "\n",
      "------------- 8th split -------------\n",
      "2021-04-22 13:54:51.843687 Epoch 1, Training loss 0.8103837167674844\n",
      "2021-04-22 13:58:39.341055 Epoch 5, Training loss 0.36806815794923087\n",
      "2021-04-22 14:03:24.531678 Epoch 10, Training loss 0.1407258357344703\n",
      "2021-04-22 14:08:11.123567 Epoch 15, Training loss 0.02893123814613897\n",
      "Accuracy Train: 0.9655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       367\n",
      "           1       0.97      0.97      0.97       415\n",
      "           2       0.95      0.99      0.97       611\n",
      "\n",
      "    accuracy                           0.97      1393\n",
      "   macro avg       0.97      0.96      0.96      1393\n",
      "weighted avg       0.97      0.97      0.97      1393\n",
      "\n",
      "[[342   7  18]\n",
      " [  1 401  13]\n",
      " [  5   4 602]]\n",
      "\n",
      "Accuracy Test: 0.9740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        40\n",
      "           1       1.00      1.00      1.00        47\n",
      "           2       0.98      0.96      0.97        67\n",
      "\n",
      "    accuracy                           0.97       154\n",
      "   macro avg       0.97      0.98      0.97       154\n",
      "weighted avg       0.97      0.97      0.97       154\n",
      "\n",
      "[[39  0  1]\n",
      " [ 0 47  0]\n",
      " [ 3  0 64]]\n",
      "\n",
      "------------- 9th split -------------\n",
      "2021-04-22 14:09:28.990513 Epoch 1, Training loss 0.836544544859366\n",
      "2021-04-22 14:13:22.096057 Epoch 5, Training loss 0.32155289534818043\n",
      "2021-04-22 14:18:05.811255 Epoch 10, Training loss 0.09655074455605989\n",
      "2021-04-22 14:22:50.220744 Epoch 15, Training loss 0.07194141971624711\n",
      "Accuracy Train: 0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       367\n",
      "           1       0.95      0.96      0.96       415\n",
      "           2       0.95      0.98      0.97       611\n",
      "\n",
      "    accuracy                           0.96      1393\n",
      "   macro avg       0.96      0.95      0.96      1393\n",
      "weighted avg       0.96      0.96      0.96      1393\n",
      "\n",
      "[[333  16  18]\n",
      " [  4 400  11]\n",
      " [  4   6 601]]\n",
      "\n",
      "Accuracy Test: 0.9351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        40\n",
      "           1       0.96      0.91      0.93        47\n",
      "           2       0.92      0.97      0.94        67\n",
      "\n",
      "    accuracy                           0.94       154\n",
      "   macro avg       0.94      0.93      0.93       154\n",
      "weighted avg       0.94      0.94      0.93       154\n",
      "\n",
      "[[36  1  3]\n",
      " [ 1 43  3]\n",
      " [ 1  1 65]]\n",
      "\n",
      "------------- 10th split -------------\n",
      "2021-04-22 14:24:07.349228 Epoch 1, Training loss 0.8286730159412731\n",
      "2021-04-22 14:27:54.338347 Epoch 5, Training loss 0.33159672502766957\n",
      "2021-04-22 14:32:39.017041 Epoch 10, Training loss 0.08622291963547468\n",
      "2021-04-22 14:37:24.511598 Epoch 15, Training loss 0.04236377403140068\n",
      "Accuracy Train: 0.9641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       367\n",
      "           1       0.98      0.97      0.97       416\n",
      "           2       0.96      0.98      0.97       610\n",
      "\n",
      "    accuracy                           0.96      1393\n",
      "   macro avg       0.96      0.96      0.96      1393\n",
      "weighted avg       0.96      0.96      0.96      1393\n",
      "\n",
      "[[342   7  18]\n",
      " [  3 405   8]\n",
      " [ 11   3 596]]\n",
      "\n",
      "Accuracy Test: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        40\n",
      "           1       1.00      0.98      0.99        46\n",
      "           2       0.97      0.99      0.98        68\n",
      "\n",
      "    accuracy                           0.98       154\n",
      "   macro avg       0.98      0.98      0.98       154\n",
      "weighted avg       0.98      0.98      0.98       154\n",
      "\n",
      "[[39  0  1]\n",
      " [ 0 45  1]\n",
      " [ 1  0 67]]\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'accuracy_result'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-25029ecfe1f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0maccuracy_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy_result'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'accuracy_result'"
     ]
    }
   ],
   "source": [
    "def kfold_evaluation(dataset):\n",
    "    X, y = zip(*dataset)\n",
    "    X = np.array([item.numpy() for item in X])\n",
    "    y = np.array(y)\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "    i = 1\n",
    "    accuracy_result = []\n",
    "    cm_result = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_train = list(zip(X_train, y_train))\n",
    "        dataset_test = list(zip(X_test, y_test))\n",
    "\n",
    "        dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "        dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "\n",
    "        print('------------- {}th split -------------'.format(i))\n",
    "\n",
    "        # perform training on dataset_train\n",
    "        model_ = CNN().to(device)\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(model_.parameters(), lr=learning_rate)\n",
    "        loss_fn = nn.CrossEntropyLoss()  # use cross entropy loss function\n",
    "\n",
    "        model_filename = 'kfold_model_balanced' + str(i) + '.pkl'\n",
    "        if model_filename not in os.listdir():\n",
    "            # call train_loop() function\n",
    "            train_loop(\n",
    "                n_epochs = 15,\n",
    "                optimizer = optimizer,\n",
    "                model = model_,\n",
    "                loss_fn = loss_fn,\n",
    "                train_loader = dataloader_train,\n",
    "                verbose=0\n",
    "            )\n",
    "            torch.save(model_, model_filename)\n",
    "        else:\n",
    "            model_ = torch.load(model_filename)\n",
    "\n",
    "        acc, cm = validate(model_, [dataloader_train, dataloader_test], ['Train', 'Test'])\n",
    "        accuracy_result.append(acc)\n",
    "        cm_result.append(cm) \n",
    "        i += 1\n",
    "\n",
    "    return accuracy_result, cm_result\n",
    "\n",
    "accuracy_result, cm_result = kfold_evaluation(total_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_result', 'wb') as f:\n",
    "    pickle.dump(accuracy_result, f)\n",
    "\n",
    "with open('cm_result', 'wb') as f2:\n",
    "    pickle.dump(cm_result, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_result_balanced, cm_result_balanced = kfold_evaluation(total_balanced_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_result_balanced', 'wb') as f3:\n",
    "    pickle.dump(accuracy_result, f3)\n",
    "\n",
    "with open('cm_result_bala', 'wb') as f4:\n",
    "    pickle.dump(cm_result, f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd016ee118533bcd0f1230a20fb580d8eca5f1b087686cdfb5f5e4aa17bc8bba119",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}