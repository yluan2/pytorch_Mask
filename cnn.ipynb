{
 "cells": [
  {
   "source": [
    "# NS_03 Group Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import datetime\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data_set, and calculate the mean and std of dataset\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # 0 -> mask  1-> nonmask  2 -> not a person\n",
    "# train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "\n",
    "# # calculate mean of imgs in each RGB channel\n",
    "# imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
    "# print(imgs.shape)\n",
    "\n",
    "# imgs.view(3, -1).mean(dim=1)  # mean of (number of imgs) in each channel\n",
    "# imgs.view(3, -1).std(dim=1) # std of (number of imgs) in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset, normarlize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "    # transforms.CenterCrop(256)   #中心剪裁后四周padding补充 (后续可以padding)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4990, 0.4567, 0.4188], std=[0.2913, 0.2778, 0.2836]) \n",
    "])\n",
    "\n",
    "# 0 -> mask  1-> nonmask  2 -> not a person\n",
    "train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder('./data/test', transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), # in=3x256x256; out=32x256x256\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=32x128x128\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1), # in=32x128x128, out=16x128x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=16x64x64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # in=16x64x64, out=8x64x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=8x32x32,\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 16x16\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64*16*16, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(1024, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(32, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv layer\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() \n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train_loop function\n",
    "def train_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_dataloader: # loop over batches in dataset\n",
    "            # move data to GPU if available\n",
    "            imgs = imgs.to(device=device)  \n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)  # feed a batch through our model\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # computes the loss\n",
    "            \n",
    "            optimizer.zero_grad()  # getting rid of the gradients from the last round\n",
    "            \n",
    "            loss.backward()  # performs backward step, compute the gradients of all parameters\n",
    "            \n",
    "            optimizer.step()  # updates the model\n",
    "            \n",
    "            loss_train += loss.item() # sums of losses we saw over the epoch\n",
    "            \n",
    "        # print the average loss per batch, in epoch%10 == 0 \n",
    "        print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch, loss_train/len(train_loader)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16837043,\n",
       " [432, 16, 2304, 16, 4608, 32, 18432, 64, 16777216, 1024, 32768, 32, 96, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model = CNN().to(device=device)  # instantiates cnn model\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list   # number of parameters, and their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['use_model.ipynb',\n",
       " '.DS_Store',\n",
       " 'use_model.py',\n",
       " 'cnn.ipynb',\n",
       " 'my_model_acc83.pkl',\n",
       " 'NS_03_evaluation.py',\n",
       " 'README.md',\n",
       " 'train_and_test.py',\n",
       " 'MaskDetection.ipynb',\n",
       " 'NS_03_part01.py',\n",
       " 'my_model.pkl',\n",
       " '.ipynb_checkpoints',\n",
       " '.git',\n",
       " 'data']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform training\n",
    "\n",
    "learning_rate = 0.001\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()  # use cross entropy loss function\n",
    "\n",
    "if 'my_model_acc83.pkl' not in os.listdir():\n",
    "    # call train_loop() function\n",
    "    train_loop(\n",
    "        n_epochs = 15,\n",
    "        optimizer = optimizer,\n",
    "        model = model,\n",
    "        loss_fn = loss_fn,\n",
    "        train_loader = train_dataloader\n",
    "    )\n",
    "    torch.save(model, 'my_model2.pkl')\n",
    "else:\n",
    "    model = torch.load('my_model_acc83.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validate function\n",
    "def validate(model, loaders, names):\n",
    "    model.eval()\n",
    "    # accuracy on training data and test data\n",
    "    for name, loader in zip(names, loaders):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_predicted = []\n",
    "        total_labels = []\n",
    "        \n",
    "        with torch.no_grad(): # do not want gradients here, as we will not want to update parameters\n",
    "            for imgs, labels in loader:\n",
    "                # move data to GPU if available\n",
    "                imgs = imgs.to(device=device)  \n",
    "                labels = labels.to(device=device)\n",
    "                total_labels.append(labels)\n",
    "                \n",
    "                # feed input to models\n",
    "                outputs = model(imgs)  \n",
    "                \n",
    "                # gives the index of the highest value as output\n",
    "                _, predicted = torch.max(outputs, dim=1)  \n",
    "                total_predicted.append(predicted)\n",
    "                \n",
    "                # counts the number of example, total is increased by the batch size\n",
    "                total += labels.shape[0]  \n",
    "            \n",
    "                # the prediction and ground truth agree\n",
    "                correct += int((predicted == labels).sum()) \n",
    "                \n",
    "        total_predicted = torch.hstack(total_predicted).cpu()\n",
    "        total_labels = torch.hstack(total_labels).cpu()\n",
    "        \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))  \n",
    "        print(sklearn.metrics.classification_report(total_labels, total_predicted))\n",
    "        print(sklearn.metrics.confusion_matrix(total_labels, total_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy train: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       284\n",
      "           1       0.94      0.94      0.94       338\n",
      "           2       0.94      0.96      0.95       576\n",
      "\n",
      "    accuracy                           0.95      1198\n",
      "   macro avg       0.95      0.94      0.95      1198\n",
      "weighted avg       0.95      0.95      0.95      1198\n",
      "\n",
      "[[264   5  15]\n",
      " [  0 318  20]\n",
      " [  6  16 554]]\n",
      "Accuracy test: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77       123\n",
      "           1       0.80      0.98      0.88       124\n",
      "           2       0.83      0.83      0.83       102\n",
      "\n",
      "    accuracy                           0.83       349\n",
      "   macro avg       0.84      0.83      0.83       349\n",
      "weighted avg       0.84      0.83      0.83       349\n",
      "\n",
      "[[ 84  23  16]\n",
      " [  1 122   1]\n",
      " [  9   8  85]]\n"
     ]
    }
   ],
   "source": [
    "# measuring accuracy\n",
    "validate(model, [train_dataloader, test_dataloader], ['train', 'test'])"
   ]
  },
  {
   "source": [
    "## Part 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Run model on Female test dataset and Male dataset, evaluate their performances.\n",
    "- Compare their performances, check whether our model has gender bias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Male: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        93\n",
      "           1       0.81      0.87      0.84       105\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79       198\n",
      "   macro avg       0.60      0.52      0.55       198\n",
      "weighted avg       0.90      0.79      0.83       198\n",
      "\n",
      "[[65 21  7]\n",
      " [ 0 91 14]\n",
      " [ 0  0  0]]\n",
      "/Users/zoufan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Accuracy Female: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78        91\n",
      "           1       0.85      0.88      0.86       109\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.61      0.51      0.55       200\n",
      "weighted avg       0.91      0.78      0.83       200\n",
      "\n",
      "[[59 17 15]\n",
      " [ 1 96 12]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('my_model_acc83.pkl')\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "male_dataset = ImageFolder('./data/test_male', transform=transform)\n",
    "male_dataloader = DataLoader(male_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "female_dataset = ImageFolder('./data/test_female', transform=transform)\n",
    "female_dataloader = DataLoader(female_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "validate(model, [male_dataloader, female_dataloader], ['Male', 'Female'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd016ee118533bcd0f1230a20fb580d8eca5f1b087686cdfb5f5e4aa17bc8bba119",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}