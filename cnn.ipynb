{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import datetime\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data_set, and calculate the mean and std of dataset\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # 0 -> mask  1-> nonmask  2 -> not a person\n",
    "# train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "\n",
    "# # calculate mean of imgs in each RGB channel\n",
    "# imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
    "# print(imgs.shape)\n",
    "\n",
    "# imgs.view(3, -1).mean(dim=1)  # mean of (number of imgs) in each channel\n",
    "# imgs.view(3, -1).std(dim=1) # std of (number of imgs) in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset, normarlize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 缩放到224 * 224\n",
    "    # transforms.CenterCrop(256)   #中心剪裁后四周padding补充 (后续可以padding)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4990, 0.4567, 0.4188], std=[0.2913, 0.2778, 0.2836]) \n",
    "])\n",
    "\n",
    "# 0 -> mask  1-> nonmask  2 -> not a person\n",
    "train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder('./data/test', transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # in=3x256x256; out=32x256x256\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=64x128x128\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), # in=32x128x128, out=16x128x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # out=16x64x64\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1), # in=16x64x64, out=8x64x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # out=8x32x32\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(8*32*32, 32*32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(32*32, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv layer\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() \n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train_loop function\n",
    "def train_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_dataloader: # loop over batches in dataset\n",
    "            # move data to GPU if available\n",
    "            imgs = imgs.to(device=device)  \n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)  # feed a batch through our model\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # computes the loss\n",
    "            \n",
    "            optimizer.zero_grad()  # getting rid of the gradients from the last round\n",
    "            \n",
    "            loss.backward()  # performs backward step, compute the gradients of all parameters\n",
    "            \n",
    "            optimizer.step()  # updates the model\n",
    "            \n",
    "            loss_train += loss.item() # sums of losses we saw over the epoch\n",
    "            \n",
    "        # print the average loss per batch, in epoch%10 == 0 \n",
    "        print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch, loss_train/len(train_loader)\n",
    "            ))\n",
    "#         if epoch == 1 or epoch % 10 == 0:\n",
    "#             print('{} Epoch {}, Training loss {}'.format(\n",
    "#                 datetime.datetime.now(), epoch, loss_train/len(train_loader)\n",
    "#             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9577499,\n",
       " [864,\n",
       "  32,\n",
       "  4608,\n",
       "  16,\n",
       "  1152,\n",
       "  8,\n",
       "  8388608,\n",
       "  1024,\n",
       "  1048576,\n",
       "  1024,\n",
       "  131072,\n",
       "  128,\n",
       "  384,\n",
       "  3])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device=device)  # instantiates cnn model\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list   # number of parameters, and their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 21:30:11.931694 Epoch 1, Training loss 1.074864489691598\n",
      "2021-03-22 21:30:26.257691 Epoch 2, Training loss 1.0409454703330994\n",
      "2021-03-22 21:30:39.946695 Epoch 3, Training loss 1.0242044636181422\n",
      "2021-03-22 21:30:53.323691 Epoch 4, Training loss 1.0109878046172005\n",
      "2021-03-22 21:31:06.813691 Epoch 5, Training loss 0.9713035259928022\n",
      "2021-03-22 21:31:20.031692 Epoch 6, Training loss 0.8964085817337036\n",
      "2021-03-22 21:31:33.213692 Epoch 7, Training loss 0.8518054434231349\n",
      "2021-03-22 21:31:46.465693 Epoch 8, Training loss 0.8142822163445609\n",
      "2021-03-22 21:31:59.948693 Epoch 9, Training loss 0.793664596761976\n",
      "2021-03-22 21:32:13.066691 Epoch 10, Training loss 0.7271166571549007\n",
      "2021-03-22 21:32:26.780691 Epoch 11, Training loss 0.6971478249345507\n",
      "2021-03-22 21:32:40.412691 Epoch 12, Training loss 0.6784423385347639\n",
      "2021-03-22 21:32:54.736693 Epoch 13, Training loss 0.6349072916167123\n",
      "2021-03-22 21:33:09.017693 Epoch 14, Training loss 0.6046038210391999\n",
      "2021-03-22 21:33:22.652208 Epoch 15, Training loss 0.5818047429834093\n",
      "2021-03-22 21:33:35.682207 Epoch 16, Training loss 0.5460593632289341\n",
      "2021-03-22 21:33:48.716207 Epoch 17, Training loss 0.5229707700865609\n",
      "2021-03-22 21:34:01.739207 Epoch 18, Training loss 0.5020929515361786\n",
      "2021-03-22 21:34:14.801206 Epoch 19, Training loss 0.45153294844286784\n",
      "2021-03-22 21:34:27.901209 Epoch 20, Training loss 0.43308789346899307\n",
      "2021-03-22 21:34:40.945206 Epoch 21, Training loss 0.4111769957201821\n",
      "2021-03-22 21:34:53.981207 Epoch 22, Training loss 0.39956938666956765\n",
      "2021-03-22 21:35:07.030207 Epoch 23, Training loss 0.35494954884052277\n",
      "2021-03-22 21:35:20.233207 Epoch 24, Training loss 0.37828153158937183\n",
      "2021-03-22 21:35:33.282206 Epoch 25, Training loss 0.36622047339166913\n",
      "2021-03-22 21:35:46.666208 Epoch 26, Training loss 0.3747329831123352\n",
      "2021-03-22 21:35:59.742206 Epoch 27, Training loss 0.2907915677343096\n",
      "2021-03-22 21:36:12.792209 Epoch 28, Training loss 0.2526373283139297\n",
      "2021-03-22 21:36:25.856207 Epoch 29, Training loss 0.2935345551797322\n",
      "2021-03-22 21:36:38.888208 Epoch 30, Training loss 0.23006038474185125\n",
      "2021-03-22 21:36:51.933207 Epoch 31, Training loss 0.18128008704100337\n",
      "2021-03-22 21:37:05.013208 Epoch 32, Training loss 0.22944614834019117\n",
      "2021-03-22 21:37:18.176206 Epoch 33, Training loss 0.15400745921901293\n",
      "2021-03-22 21:37:31.219206 Epoch 34, Training loss 0.1738551305340869\n",
      "2021-03-22 21:37:44.266206 Epoch 35, Training loss 0.10113237085086958\n",
      "2021-03-22 21:37:57.316209 Epoch 36, Training loss 0.14601865602391106\n",
      "2021-03-22 21:38:10.438207 Epoch 37, Training loss 0.1189464887071933\n",
      "2021-03-22 21:38:23.516207 Epoch 38, Training loss 0.20050220659800938\n",
      "2021-03-22 21:38:36.578206 Epoch 39, Training loss 0.08232258930802346\n",
      "2021-03-22 21:38:49.613207 Epoch 40, Training loss 0.08255664354988507\n",
      "2021-03-22 21:39:02.692206 Epoch 41, Training loss 0.1059394011007888\n",
      "2021-03-22 21:39:15.904206 Epoch 42, Training loss 0.0661330303975514\n",
      "2021-03-22 21:39:28.936206 Epoch 43, Training loss 0.2308174879955394\n",
      "2021-03-22 21:39:42.026206 Epoch 44, Training loss 0.09467522998207382\n",
      "2021-03-22 21:39:55.113206 Epoch 45, Training loss 0.07269885156835829\n",
      "2021-03-22 21:40:08.248206 Epoch 46, Training loss 0.042746738750221475\n",
      "2021-03-22 21:40:21.335208 Epoch 47, Training loss 0.03728939913811961\n",
      "2021-03-22 21:40:34.515208 Epoch 48, Training loss 0.015753565173197006\n",
      "2021-03-22 21:40:47.549206 Epoch 49, Training loss 0.08939271015115083\n",
      "2021-03-22 21:41:00.607207 Epoch 50, Training loss 0.11338750696075814\n"
     ]
    }
   ],
   "source": [
    "# perform training\n",
    "\n",
    "learning_rate = 0.02\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()  # use cross entropy loss function\n",
    "\n",
    "# call train_loop() function\n",
    "train_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validate function\n",
    "def validate(model, train_loader, test_loader):\n",
    "    model.eval()\n",
    "    # accuracy on training data and test data\n",
    "    for name, loader in [(\"train\", train_loader), (\"test\", test_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_predicted = []\n",
    "        total_labels = []\n",
    "        \n",
    "        with torch.no_grad(): # do not want gradients here, as we will not want to update parameters\n",
    "            for imgs, labels in loader:\n",
    "                # move data to GPU if available\n",
    "                imgs = imgs.to(device=device)  \n",
    "                labels = labels.to(device=device)\n",
    "                total_labels.append(labels)\n",
    "                \n",
    "                outputs = model(imgs)  # feed input to models\n",
    "                \n",
    "                _, predicted = torch.max(outputs, dim=1)  # gives the index of the highest value as output\n",
    "                total_predicted.append(predicted)\n",
    "                \n",
    "                total += labels.shape[0]  # counts the number of example, total is increased by the batch size\n",
    "                \n",
    "                # comparing the predicted class that had the maximum probability and the ground-truth labels,\n",
    "                # we first get a Boolean array. Taking the sum gives the number of items in the batch where \n",
    "                # the prediction and ground truth agree\n",
    "                correct += int((predicted == labels).sum()) \n",
    "                \n",
    "        total_predicted = torch.hstack(total_predicted).cpu()\n",
    "        total_labels = torch.hstack(total_labels).cpu()\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))  \n",
    "        print(sklearn.metrics.classification_report(total_labels, total_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "Accuracy train: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       270\n",
      "           1       1.00      1.00      1.00       270\n",
      "           2       1.00      1.00      1.00       576\n",
      "\n",
      "    accuracy                           1.00      1116\n",
      "   macro avg       1.00      1.00      1.00      1116\n",
      "weighted avg       1.00      1.00      1.00      1116\n",
      "\n",
      "4\n",
      "4\n",
      "Accuracy test: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62        30\n",
      "           1       1.00      0.67      0.80        30\n",
      "           2       0.74      0.85      0.79        60\n",
      "\n",
      "    accuracy                           0.75       120\n",
      "   macro avg       0.78      0.72      0.74       120\n",
      "weighted avg       0.77      0.75      0.75       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measuring accuracy\n",
    "validate(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# ignore below ##########################################################\n",
    "\n",
    "# # !pip install skorch\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.d = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.d[idx][0], self.d[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m1.0775\u001b[0m  22.5910\n",
      "      2        \u001b[36m1.0611\u001b[0m  22.1830\n",
      "      3        \u001b[36m1.0497\u001b[0m  22.4300\n",
      "      4        \u001b[36m1.0406\u001b[0m  23.2660\n",
      "      5        \u001b[36m1.0350\u001b[0m  23.0540\n"
     ]
    }
   ],
   "source": [
    "nn_classifier = NeuralNetClassifier(\n",
    "    module=CNN,\n",
    "    max_epochs=5,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.01,\n",
    "    batch_size=32,\n",
    "    optimizer=optim.SGD,\n",
    "    device=torch.device('cuda'),\n",
    "    train_split=None\n",
    ")\n",
    "\n",
    "# call fit(X, y) to train data\n",
    "train_dataset = ImageFolder('./data/train', transform=transform)\n",
    "train_dataset_skorch = SkorchDataset(train_dataset)\n",
    "\n",
    "nn_classifier.fit(train_dataset_skorch, y=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 2 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       270\n",
      "           1       0.00      0.00      0.00       270\n",
      "           2       0.52      1.00      0.68       576\n",
      "\n",
      "    accuracy                           0.52      1116\n",
      "   macro avg       0.17      0.33      0.23      1116\n",
      "weighted avg       0.27      0.52      0.35      1116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on training data\n",
    "y_pred_train = nn_classifier.predict(train_dataset_skorch)\n",
    "print(y_pred_train)\n",
    "y_train = np.array([y for x, y in iter(train_dataset)])\n",
    "\n",
    "# print classification report\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.50      1.00      0.67        60\n",
      "\n",
      "    accuracy                           0.50       120\n",
      "   macro avg       0.17      0.33      0.22       120\n",
      "weighted avg       0.25      0.50      0.33       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = nn_classifier.predict(SkorchDataset(test_dataset))\n",
    "print(y_pred)\n",
    "y_test = np.array([y for x, y in iter(test_dataset)])\n",
    "\n",
    "# print classification report\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
